{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43613e7",
   "metadata": {},
   "source": [
    "# GP 教程-E02: 一小时上手的简单GP\n",
    "作者: Wei W. Xing (wxing.me) <br />\n",
    "翻译: Yuxin Wang\n",
    "日期: 2022-03-28    <br />\n",
    "\n",
    "摘要: 现如今高斯过程已经是一个长期存在并且广泛被应用的技术，并且也有很多有用的教程、课本、文章以及博客，但是我发现很多学生（包括学生时代的我）都曾经在将GP应用到实际问题这个过程中碰壁。我认为学会一个东西最简单的方法就是应用它而不是准备很多必要的数学背景或者深入理论。因此我准写了这篇教程，希望可以用一种比较直接的方式来应用GP这个技术，尤其是为了工科的学生们。希望这篇教程能有所帮助。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ed342",
   "metadata": {},
   "source": [
    "在这篇教程中，我们希望可以考虑最简单的一维输出的例子，也就是，$y \\in \\mathcal{R}^1$，是一维标量。相对应的\n",
    "$\\mathcal{x} \\in \\mathcal{R}^D$，输入的是一个D维的向量。\n",
    "那么让我们开始吧～ 由于这篇应用是基于Torch开发的，所以我们将从导入Torch库作为开端。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c77362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "print(torch.__version__)\n",
    "# I use torch (1.11.0) for this work. lower version may not work.\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # Fixing strange error if run in MacOS \n",
    "\n",
    "JITTER = 1e-6\n",
    "EPS = 1e-10\n",
    "PI = 3.1415"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d3d8c",
   "metadata": {},
   "source": [
    "#### 1. 生成综合数据\n",
    "将$y = (6x-2)^2sin(12x-4)$作为我们的目标拟合函数。我们将需要产生包含32组样本点的训练数据集$xtr, ytr$ 以及包含100组数据的测试数据集$xte, yte$ 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7692b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtr.size: torch.Size([32, 1]) ytr.size: torch.Size([32, 1])\n",
      "xte.size: torch.Size([100, 1]) yte.size: torch.Size([100, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_set\n",
    "xtr = torch.rand(32, 1)\n",
    "ytr = ((6*xtr - 2)**2) * torch.sin(12*xtr - 4) + torch.randn(32, 1) * 1\n",
    "\n",
    "#test_set\n",
    "xte = torch.linspace(0, 1, 100).view(-1,1)\n",
    "yte = ((6*xte - 2)**2) * torch.sin(12*xte - 4)\n",
    "\n",
    "#plot the data\n",
    "print(\"xtr.size:\", xtr.size(), \"ytr.size:\", ytr.size())\n",
    "print(\"xte.size:\", xte.size(), \"yte.size:\", yte.size())\n",
    "plt.plot(xtr.numpy(), ytr.numpy(), 'b+')\n",
    "plt.plot(xte.numpy(), yte.numpy(), 'r-', alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32aeed6",
   "metadata": {},
   "source": [
    "#### 2. 核函数以及模型参数（超参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97c038",
   "metadata": {},
   "source": [
    "我们需要优化的函数是：均值函数以及核函数。但是优化一个“函数”并不是就想所说的那么简单， 因此我们需要给丁这些函数的特定形式，之后再去优化他们的参数。在这篇教程中，我们设定均值函数为零（不需要优化均值函数）。而核函数部分，我们使用最常用的automatic relevance determinant（ARD）核函数：\n",
    "$$k_{ard}(\\mathbf{x}, \\mathbf{x}') = a \\cdot \\exp(-\\frac{1}{2} \\sum_{d=1}^D{ (\\frac{x_d-x'_d}{l_d}})^2 )$$\n",
    "其中$a$是核函数的振幅，$l_d$是输入变量$x$的d维输入${x}_d$的长度系数（length scale）。$\\mathbf{l}$ 控制着每个输入维度的贡献量，比如：$l_d$数值越大，则${x}_d$相比于其他维度在系统中的贡献越大；反之亦然。因此，这个函数被称为ARD，即可以自动控制相关性。 <br />\n",
    "\n",
    "在开始编程之前还有另一件事情需要注意，$l_d$和$a$均为正参数。所以如果我们直接将他们定义为torch中的参数torch.parameters，则在优化过程中有可能导致$l_d$和$a$被计算成负数。因此我们需要特别注意确保$l_d$和$a$在过程中为正数。一个简单的方法就是，用他们取log之后的值来定义，而使用的时候再将其转换为其指数值。 <br />\n",
    "\n",
    " 那么现在我们可以定义核函数了，其返回值为输入两组数据的一个核矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2190321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel parameters\n",
    "log_length_scale = nn.Parameter(torch.zeros(xte.size(1)))\n",
    "log_scale = nn.Parameter(torch.zeros(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "019a10f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8717, 0.7607,  ..., 0.9929, 0.7489, 0.9879],\n",
      "        [0.8717, 1.0000, 0.9770,  ..., 0.8128, 0.9725, 0.7935],\n",
      "        [0.7607, 0.9770, 1.0000,  ..., 0.6913, 0.9998, 0.6696],\n",
      "        ...,\n",
      "        [0.9929, 0.8128, 0.6913,  ..., 1.0000, 0.6789, 0.9993],\n",
      "        [0.7489, 0.9725, 0.9998,  ..., 0.6789, 1.0000, 0.6571],\n",
      "        [0.9879, 0.7935, 0.6696,  ..., 0.9993, 0.6571, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "def kernel(X1, X2, log_length_scale, log_scale): \n",
    "    length_scale = torch.exp(log_length_scale)\n",
    "    K = torch.zeros(X1.size(0), X2.size(0))\n",
    "    \n",
    "    for i in range(X1.size(0)):\n",
    "        for j in range(X2.size(0)):\n",
    "            for d in range(X1.size(1)):\n",
    "                K[i,j] = torch.exp(-0.5 * ((X1[i,d] - X2[j,d])**2 / length_scale[d]**2).sum() ) * torch.exp(log_scale)\n",
    "    return K\n",
    "\n",
    "K1 = kernel(xtr, xtr, log_length_scale, log_scale)\n",
    "print(K1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cd531",
   "metadata": {},
   "source": [
    "然而，在编程过程中我们应该尽可能的避免使用循环结构，这是以内循环会导致消耗大量的内存以及时间。因此我们将用另一种方法来撰写核函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c88c4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8717, 0.7607,  ..., 0.9929, 0.7489, 0.9879],\n",
      "        [0.8717, 1.0000, 0.9770,  ..., 0.8128, 0.9725, 0.7935],\n",
      "        [0.7607, 0.9770, 1.0000,  ..., 0.6913, 0.9998, 0.6696],\n",
      "        ...,\n",
      "        [0.9929, 0.8128, 0.6913,  ..., 1.0000, 0.6789, 0.9993],\n",
      "        [0.7489, 0.9725, 0.9998,  ..., 0.6789, 1.0000, 0.6571],\n",
      "        [0.9879, 0.7935, 0.6696,  ..., 0.9993, 0.6571, 1.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor(5.7171e-07, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "def kernel(X1, X2, log_length_scale, log_scale): # 定义核函数没有加linear\n",
    "\n",
    "    X1 = X1 / log_length_scale.exp()\n",
    "    X2 = X2 / log_length_scale.exp()\n",
    "\n",
    "    X1_norm2 = X1 * X1\n",
    "    X2_norm2 = X2 * X2\n",
    "\n",
    "    K = -2.0 * X1 @ X2.t() + X1_norm2.expand(X1.size(0), X2.size(0)) + X2_norm2.t().expand(X1.size(0), X2.size(0))  #this is the effective Euclidean distance matrix between X1 and X2.\n",
    "    K = log_scale.exp() * torch.exp(-0.5 * K)\n",
    "    return K\n",
    "\n",
    "K2 = kernel(xtr, xtr, log_length_scale, log_scale)\n",
    "print(K2)\n",
    "print( (K1 - K2).norm() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf0429",
   "metadata": {},
   "source": [
    "我们可以看到两个核函数的结果是相通的，然而执行的时间却又很大的不同，我们还可以将训练数据的样本量增大来验证这种差异。    <br />\n",
    "\n",
    "此外，我们还需要定义GP中的噪声$\\sigma^2$。为了能够更简单地在今后的教程中介绍共轭先验只是，我们选择使用$\\sigma^2$的逆$\\beta=1/\\sigma^2$来定义噪声，而不是直接定义$\\sigma^2$，并且与长度系数核振幅相同，我们也需要确保噪声的值恒为正数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34dba8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_beta = nn.Parameter(torch.ones(1) * -4) # this is a large noise. we optimize to shrink it to a proper value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c072b",
   "metadata": {},
   "source": [
    "#### 3. 似然函数的负对数（negative log likelihood）\n",
    "对于大部分回归问题，我们需要对已定义好的损失函数求最小值。那么在GP中，损失函数就是似然函数值的负对数。\n",
    "\n",
    "因为我们需要对损失函数最小化，所以我们选择将似然函数取对数后再取相反数，并且由于似然函数值的对数有更为清晰的形式，并且不改变函数的单调性，所以对似然函数值取对数。\n",
    "\n",
    "似然函数的负对数形式为：\n",
    "$$L=-\\frac{1}{2}\\mathbf{y}^T (\\mathbf{K}+\\sigma^2 \\mathbf{I})^{-1}\\mathbf{y}-\\frac{1}{2}\\log(|\\mathbf{K}+\\sigma^2 \\mathbf{I}|)-\\frac{n}{2}log(2\\pi)$$\n",
    "其中$\\mathbf{y}$是将观测数据按照$N\\times1$向量形式排列，$\\mathbf{K}$是训练数据的大小为N\\times N$的核矩阵。$\\sigma^2$是噪声方差，并且$\\mathbf{I}$是单位矩阵。\n",
    "\n",
    "接下来我们用$\\mathbf{\\Sigma}=\\mathbf{K}+\\sigma^2 \\mathbf{I}$来代替核矩阵的逆，则损失函数可以写为：\n",
    "$$nll=\\frac{1}{2}\\mathbf{y}^T\\mathbf{\\Sigma}^{-1}\\mathbf{y}+\\frac{1}{2}\\log(|\\mathbf{\\Sigma}|)+\\frac{n}{2}log(2\\pi)$$\n",
    "\n",
    "我们虽然可以利用以后的损失函数值直接进行计算以及优化，但是由于求维度较高的矩阵的逆同样会十分占用时间与内存，因此，我们应该避免这种计算，而此采用另一个技巧（Cholesky 分解）来更佳高效稳定的计算。\n",
    "\n",
    "首先，计算核矩阵的cholesky分解：\n",
    "$\\mathbf{\\Sigma} = \\mathbf{L} \\mathbf{L}^T$\n",
    "所以在似然函数的负对数表达式中的第一项，可以推导为：\n",
    "$$ \\mathbf{y}^T (\\mathbf{K}+\\sigma^2 \\mathbf{I})^{-1}\\mathbf{y} = \\mathbf{y}^T (\\mathbf{L} \\mathbf{L}^T)^{-1} \\mathbf{y} = \\mathbf{y}^T \\mathbf{L}^{-T} \\mathbf{L}^{-1} \\mathbf{y}  = (\\mathbf{L}^{-1} \\mathbf{y})^T \\mathbf{L}^{-1} \\mathbf{y}  $$\n",
    "这个公式让我们通过解一个线性方程组的方式，$\\mathbf{L} \\mathbf{\\gamma} = \\mathbf{y}$，避免了矩阵求逆所带来的资源的浪费，并且给出了$\\mathbf{L}^{-1} \\mathbf{y} = \\mathbf{\\gamma}$。所以如果我们获得了$\\mathbf{\\gamma}$，我们就能够计算表达式中的第一项，也就是$\\mathbf{\\gamma}$的二范数。\n",
    "\n",
    "之后我们可以计算损失函数表达式中的第二项，即\n",
    "$$ \\log(|\\mathbf{\\Sigma}|) = \\log(| \\mathbf{L} \\mathbf{L}^T |) =  \\log(|\\mathbf{L}| |\\mathbf{L}^T|) = \\log(\\prod_{i=1}^{N} L_{ii} \\prod_{i=1}^{N} L_{ii}) = 2\\sum_{i=1}^{N}\\log(L_{ii})$$\n",
    "\n",
    "在经过了以上两个部分之后，损失函数可以表达为：\n",
    "$$nll=\\frac{1}{2} \\mathbf{\\gamma}^T \\mathbf{\\gamma} + \\sum_{i=1}^{N}\\log(L_{ii}) + \\frac{n}{2}log(2\\pi)$$\n",
    "\n",
    "那么接下来，我们一起将这个过程用代码表达出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3b4cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(X, Y, log_length_scale, log_scale, log_beta):\n",
    "    y_num = Y.size(0)\n",
    "    Sigma = kernel(X, X, log_length_scale, log_scale) + log_beta.exp().pow(-1) * torch.eye(X.size(0)) + JITTER * torch.eye(X.size(0))   # add JITTER here to avoid singularity\n",
    "    \n",
    "    L = torch.linalg.cholesky(Sigma)\n",
    "    #option 1 (use this if torch supports)\n",
    "    gamma,_ = torch.triangular_solve(Y, L, upper = False)\n",
    "    # print(gamma.shape)\n",
    "    # print(\"gamma **2:\")\n",
    "    # print((gamma**2).sum())\n",
    "    # print(\"gamma.T@gamma\")\n",
    "    # print(gamma.T@gamma)\n",
    "    #option 2\n",
    "    # gamma = L.inverse() @ Y       # we can use this as an alternative because L is a lower triangular matrix.\n",
    "    \n",
    "    nll =  0.5 * (gamma ** 2).sum() +  L.diag().log().sum()  + 0.5 * y_num * torch.log(2 * torch.tensor(PI))\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee918d5",
   "metadata": {},
   "source": [
    "补充：(by zhenjie)<br/>\n",
    "gamma,_ = torch.triangular_solve(Y, L, upper = False)<br/>\n",
    "这里使用了torch.triangular_solve 函数，该函数用于解决三角线性系统。具体来说，它解决以下形式的线性系统方程： AX=B<br/>\n",
    "其中 A 是一个上三角或下三角矩阵（由参数 upper 决定），X 是未知矩阵，B 是已知矩阵。<br/>\n",
    "在这个代码中，Y 是已知矩阵，L 是下三角矩阵，gamma 是解矩阵<br/>\n",
    "具体而言，torch.triangular_solve(Y, L, upper=False) 的调用是将 Y 视为右侧矩阵，L 视为下三角矩阵，通过解决 LX=Y 来计算解矩阵 gamma。<br/>\n",
    "gamma 将是解矩阵，满足 L ⋅ gamma = Y。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd16b4d",
   "metadata": {},
   "source": [
    "#### 4. 调用优化器\n",
    "当损失函数，也就是似然函数的负对数定义好之后，我们可以很简单地通过调用优化器来最小化损失函数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28a06a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 nnl:102.83882\n",
      "iter 1 nnl:102.77118\n",
      "iter 2 nnl:102.70448\n",
      "iter 3 nnl:102.63876\n",
      "iter 4 nnl:102.57405\n"
     ]
    }
   ],
   "source": [
    "def train_adam(X, Y, log_length_scale, log_scale, log_beta, niter = 50, lr = 0.001):\n",
    "    optimizer = torch.optim.Adam([log_beta, log_length_scale, log_scale], lr = lr)\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(niter):\n",
    "        optimizer.zero_grad()\n",
    "        # self.update()\n",
    "        loss = negative_log_likelihood(X, Y, log_length_scale, log_scale, log_beta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print the nll\n",
    "        # print('iter', i, ' nnl:', loss.item())\n",
    "        print('iter', i, 'nnl:{:.5f}'.format(loss.item()))\n",
    "        # print the likelihood\n",
    "        # print('iter', i, 'nnl:{:.5f}'.format(loss.item()),'likelihood:{:.9f}'.format((-loss).exp().item()) )\n",
    "        \n",
    "train_adam(xtr, ytr,log_length_scale, log_scale, log_beta, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd16b4d",
   "metadata": {},
   "source": [
    "#### 5. 预测 Predictive Prosterior "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458b3b3",
   "metadata": {},
   "source": [
    "当超参数优化完毕之后，我们可以根据如下的公式对预测后验分布进行计算：\n",
    "\\begin{aligned}\n",
    "&\\mu=\\mathbf{k}^* \\Sigma^{-1} \\mathbf{y}\\\\\n",
    "&s^2=\\mathbf{k}_{**}- (\\mathbf{k}^*)^T \\mathbf{\\Sigma}^{-1} \\mathbf{k}^* + {1}/{\\beta}\\\\\n",
    "\\end{aligned}\n",
    "如上文我们所提到的一样，我们应该尽可能的避免计算矩阵的逆。所以我们将再次次啊用cholesky分解以获得预测后验。\n",
    "\n",
    "首先我们定义 $\\mathbf{\\Sigma}^{-1} \\mathbf{y} =  \\mathbf{\\alpha}$，这个方法经常在文献和开放源代码中使用。引入 $\\mathbf{\\alpha}$ 的优点是：<br />\n",
    "1）我们可以使用cholesky分解计算预测后验；<br />\n",
    "2）节省内存并提供更快去的后验预测（不需要计算逆矩阵）<br />\n",
    "通过使用 $\\mathbf{L}$ 以获得 $\\mathbf{\\alpha}$, 我们首先解决了 $\\mathbf{L} \\mathbf{\\gamma} = \\mathbf{y}$，之后在计算 $\\mathbf{L}^T \\mathbf{y} = \\mathbf{\\gamma}$, 如你所见，有时会写成一种简洁的形式\n",
    "$$\\mathbf{\\alpha} = \\mathbf{L}^T \\backslash \\mathbf{L} \\backslash \\mathbf{y}$$\n",
    "\n",
    "$(\\mathbf{k}^*)^T \\mathbf{\\Sigma}^{-1} \\mathbf{k}^*$ 的计算则很类似 $\\mathbf{\\gamma}^T \\mathbf{\\gamma}$ 在之前提到的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2a7a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, Xte, log_length_scale, log_scale, log_beta, Y):\n",
    "    n_test = Xte.size(0)\n",
    "    Sigma = kernel(X, X, log_length_scale, log_scale) + log_beta.exp().pow(-1) * torch.eye(\n",
    "        X.size(0)) + JITTER * torch.eye(X.size(0))\n",
    "    kx = kernel(X, Xte, log_length_scale, log_scale)\n",
    "    L = torch.cholesky(Sigma)\n",
    "    \n",
    "    # option 1\n",
    "    mean = kx.t() @ torch.cholesky_solve(Y, L)  # torch.linalg.cholesky()\n",
    "    # option 2\n",
    "    # mean = kx @ torch.L.t().inverse() @ L.inverse() @ Y\n",
    "    \n",
    "    # LinvKx = L.inverse() @ kx.t()  # TODO: the inverse for L should be cheap. check this.\n",
    "        # torch.cholesky_solve(kx.t(), L)\n",
    "    LinvKx,_ = torch.triangular_solve(kx, L, upper = False)\n",
    "    # option 1, standard way\n",
    "    # var_diag = kernel(Xte, Xte, log_length_scale, log_scale).diag().view(-1,1) - (LinvKx.t() @ LinvKx).diag().view(-1, 1)\n",
    "    # option 2, a faster way\n",
    "    var_diag = log_scale.exp().expand(n_test, 1) - (LinvKx**2).sum(dim = 0).view(-1, 1)\n",
    "    \n",
    "    var_diag = var_diag + log_beta.exp().pow(-1)\n",
    "    return mean, var_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b00a1",
   "metadata": {},
   "source": [
    "#### 5. 测试与验证\n",
    "我们将在综合数据集上应用GP模型，并将结果可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c1078f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 nnl:102.51033\n",
      "iter 1 nnl:101.92053\n",
      "iter 2 nnl:101.42941\n",
      "iter 3 nnl:101.04358\n",
      "iter 4 nnl:100.76581\n",
      "iter 5 nnl:100.59152\n",
      "iter 6 nnl:100.50455\n",
      "iter 7 nnl:100.47401\n",
      "iter 8 nnl:100.45668\n",
      "iter 9 nnl:100.40707\n",
      "iter 10 nnl:100.29047\n",
      "iter 11 nnl:100.08932\n",
      "iter 12 nnl:99.80045\n",
      "iter 13 nnl:99.42682\n",
      "iter 14 nnl:98.96941\n",
      "iter 15 nnl:98.42157\n",
      "iter 16 nnl:97.76694\n",
      "iter 17 nnl:96.98277\n",
      "iter 18 nnl:96.04974\n",
      "iter 19 nnl:94.96342\n",
      "iter 20 nnl:93.73794\n",
      "iter 21 nnl:92.39982\n",
      "iter 22 nnl:90.98499\n",
      "iter 23 nnl:89.54336\n",
      "iter 24 nnl:88.13529\n",
      "iter 25 nnl:86.81189\n",
      "iter 26 nnl:85.59512\n",
      "iter 27 nnl:84.47242\n",
      "iter 28 nnl:83.40781\n",
      "iter 29 nnl:82.35940\n",
      "iter 30 nnl:81.29222\n",
      "iter 31 nnl:80.18121\n",
      "iter 32 nnl:79.00968\n",
      "iter 33 nnl:77.76864\n",
      "iter 34 nnl:76.45632\n",
      "iter 35 nnl:75.07997\n",
      "iter 36 nnl:73.65873\n",
      "iter 37 nnl:72.22557\n",
      "iter 38 nnl:70.82964\n",
      "iter 39 nnl:69.53761\n",
      "iter 40 nnl:68.43094\n",
      "iter 41 nnl:67.58779\n",
      "iter 42 nnl:67.02991\n",
      "iter 43 nnl:66.63993\n",
      "iter 44 nnl:66.20660\n",
      "iter 45 nnl:65.62907\n",
      "iter 46 nnl:64.99395\n",
      "iter 47 nnl:64.48062\n",
      "iter 48 nnl:64.22082\n",
      "iter 49 nnl:64.22034\n",
      "iter 50 nnl:64.37742\n",
      "iter 51 nnl:64.57644\n",
      "iter 52 nnl:64.72988\n",
      "iter 53 nnl:64.80312\n",
      "iter 54 nnl:64.81157\n",
      "iter 55 nnl:64.79819\n",
      "iter 56 nnl:64.82087\n",
      "iter 57 nnl:64.89823\n",
      "iter 58 nnl:64.97167\n",
      "iter 59 nnl:64.95901\n",
      "iter 60 nnl:64.84000\n",
      "iter 61 nnl:64.66454\n",
      "iter 62 nnl:64.51507\n",
      "iter 63 nnl:64.41807\n",
      "iter 64 nnl:64.36834\n",
      "iter 65 nnl:64.33143\n",
      "iter 66 nnl:64.28325\n",
      "iter 67 nnl:64.22572\n",
      "iter 68 nnl:64.16965\n",
      "iter 69 nnl:64.13360\n",
      "iter 70 nnl:64.12778\n",
      "iter 71 nnl:64.14826\n",
      "iter 72 nnl:64.17840\n",
      "iter 73 nnl:64.19981\n",
      "iter 74 nnl:64.20626\n",
      "iter 75 nnl:64.20060\n",
      "iter 76 nnl:64.19360\n",
      "iter 77 nnl:64.19252\n",
      "iter 78 nnl:64.19656\n",
      "iter 79 nnl:64.19936\n",
      "iter 80 nnl:64.19620\n",
      "iter 81 nnl:64.18265\n",
      "iter 82 nnl:64.16426\n",
      "iter 83 nnl:64.14374\n",
      "iter 84 nnl:64.12840\n",
      "iter 85 nnl:64.11925\n",
      "iter 86 nnl:64.11295\n",
      "iter 87 nnl:64.10834\n",
      "iter 88 nnl:64.10258\n",
      "iter 89 nnl:64.09432\n",
      "iter 90 nnl:64.09055\n",
      "iter 91 nnl:64.08875\n",
      "iter 92 nnl:64.09208\n",
      "iter 93 nnl:64.09582\n",
      "iter 94 nnl:64.09964\n",
      "iter 95 nnl:64.10143\n",
      "iter 96 nnl:64.10173\n",
      "iter 97 nnl:64.10069\n",
      "iter 98 nnl:64.10052\n",
      "iter 99 nnl:64.10223\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_adam(xtr, ytr, log_length_scale, log_scale, log_beta, 100, 0.1)\n",
    "with torch.no_grad():\n",
    "    ypred, yvar = forward(xtr, xte, log_length_scale, log_scale, log_beta, ytr)\n",
    "    \n",
    "plt.errorbar(xte.numpy().reshape(100), ypred.detach().numpy().reshape(100),\n",
    "             yerr=yvar.sqrt().squeeze().detach().numpy(), fmt='r-.', alpha=0.2)\n",
    "plt.plot(xtr.numpy(), ytr.numpy(), 'b+')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
